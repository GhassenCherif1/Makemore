{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"names.txt\",\"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi = { s:i+1 for i,s in enumerate(chars) }\n",
    "stoi[\".\"] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182511, 3]) torch.Size([182511])\n",
      "torch.Size([22813, 3]) torch.Size([22813])\n",
      "torch.Size([22822, 3]) torch.Size([22822])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.1 * len(words))\n",
    "def build_dataset(words):\n",
    "    X,Y = [],[]\n",
    "    for w in words:\n",
    "        #print(w)\n",
    "        chars = \".\"*block_size + w + \".\" \n",
    "        for i in range(len(chars)-block_size):\n",
    "            X.append([stoi[ix] for ix in chars[i:i+block_size]])\n",
    "            Y.append(stoi[chars[i+block_size]])\n",
    "            #print(f\"{chars[i:i+n]} -> {chars[i+n]}\")\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape,Y.shape)\n",
    "    return(X,Y)\n",
    "import random\n",
    "random.shuffle(words)\n",
    "Xtr , Ytr = build_dataset(words[:n1])\n",
    "Xdev , Ydev = build_dataset(words[n1:n1+n2])\n",
    "Xtest , Ytest = build_dataset(words[n1+n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 100\n",
    "n_emb = 2\n",
    "bngain = torch.ones((1,n_hidden))\n",
    "bnbias = torch.zeros((1,n_hidden))\n",
    "g = torch.Generator().manual_seed(21715050)\n",
    "C = torch.randn((27,n_emb),generator=g)\n",
    "W1 = torch.randn(((n_emb * block_size),n_hidden),generator=g) * 0.2\n",
    "b1 = torch.randn((n_hidden),generator=g) *0.01\n",
    "W2 = torch.randn((n_hidden,27),generator=g) * 0.01\n",
    "b2 = torch.randn((27),generator=g) * 0.01\n",
    "parameters = [C,W1,b1,W2,b2,bngain,bnbias]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6273841857910156\n",
      "2.7433834075927734\n",
      "2.8380520343780518\n",
      "2.6460659503936768\n",
      "2.844289541244507\n",
      "2.7873127460479736\n",
      "2.9730064868927\n",
      "2.6482222080230713\n",
      "2.5687053203582764\n",
      "2.5275919437408447\n",
      "2.7114365100860596\n",
      "3.0328025817871094\n",
      "2.5273687839508057\n",
      "2.4105594158172607\n",
      "2.8540399074554443\n",
      "2.6271586418151855\n",
      "2.580650568008423\n",
      "2.5679709911346436\n",
      "2.4741382598876953\n",
      "2.7595698833465576\n",
      "2.5418295860290527\n",
      "2.845902681350708\n",
      "2.4740662574768066\n",
      "2.819683074951172\n",
      "2.450183153152466\n",
      "2.6271297931671143\n",
      "2.5503485202789307\n",
      "2.447953224182129\n",
      "2.6877286434173584\n",
      "2.634307622909546\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "max_steps = 3000\n",
    "for i in range(max_steps):\n",
    "\n",
    "    ix =  torch.randint(0,Xtr.shape[0],(batch_size,))    \n",
    "    # forward pass\n",
    "    emb = C[Xtr][ix] # (32,3,2)\n",
    "    embcat = emb.view(-1,n_emb*block_size)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    hpreact =  bngain* (hpreact - hpreact.mean(0,keepdim=True))/ hpreact.std(0,keepdim=True) + bnbias\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # probs = counts / counts.sum(1,keepdim=True)\n",
    "    # loss = -probs[torch.arange(32),Y].log().mean()\n",
    "    loss = F.cross_entropy(logits,Ytr[ix])\n",
    "    if(i % 100 == 0):\n",
    "        print(loss.item())\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # update\n",
    "    lr = 0.1 if i<2000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -0.007 * p.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 10.,  16.,  14.,  35.,  46.,  57.,  58.,  62.,  40.,  50.,  53.,\n",
       "         65.,  77.,  73.,  94.,  91.,  73.,  67., 103., 105.,  98., 104.,\n",
       "         83.,  74., 117.,  96., 120., 105.,  92., 100.,  86.,  95.,  53.,\n",
       "         74.,  72.,  75.,  75.,  58.,  76.,  39.,  52.,  51.,  48.,  49.,\n",
       "         32.,  18.,  24.,  25.,  12.,   8.]),\n",
       " array([-0.94490361, -0.90720687, -0.86951013, -0.83181339, -0.79411665,\n",
       "        -0.75641991, -0.71872318, -0.68102644, -0.6433297 , -0.60563296,\n",
       "        -0.56793622, -0.53023948, -0.49254274, -0.454846  , -0.41714926,\n",
       "        -0.37945252, -0.34175578, -0.30405904, -0.2663623 , -0.22866556,\n",
       "        -0.19096882, -0.15327208, -0.11557534, -0.07787861, -0.04018187,\n",
       "        -0.00248513,  0.03521161,  0.07290835,  0.11060509,  0.14830183,\n",
       "         0.18599857,  0.22369531,  0.26139205,  0.29908879,  0.33678553,\n",
       "         0.37448227,  0.41217901,  0.44987575,  0.48757249,  0.52526923,\n",
       "         0.56296597,  0.6006627 ,  0.63835944,  0.67605618,  0.71375292,\n",
       "         0.75144966,  0.7891464 ,  0.82684314,  0.86453988,  0.90223662,\n",
       "         0.93993336]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(h.view(-1).tolist(),50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(-1,n_emb*block_size)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    bnmean = hpreact.mean(0,keepdim=True)\n",
    "    bnstd = hpreact.std(0,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.6270530223846436\n",
      "val 2.629551887512207\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "        \"train\": (Xtr,Ytr),\n",
    "        \"val\": (Xdev,Ydev),\n",
    "        \"test\":(Xtest,Ytest)\n",
    "    }[split]\n",
    "    emb = C[x]\n",
    "    embcat = emb.view(-1,n_emb*block_size)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    hpreact =  bngain* (hpreact - bnmean)/ (bnstd+0.01) + bnbias\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits,y)\n",
    "    print(split , loss.item())\n",
    "split_loss(\"train\")\n",
    "split_loss(\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original:\n",
    "train 2.71\n",
    "val 2.705\n",
    "fix softmax initializations:\n",
    "train 2.5763285160064697\n",
    "val 2.5684869289398193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):    \n",
    "    out = []\n",
    "    context = [0]*block_size\n",
    "    while True:\n",
    "        emb = C[context]\n",
    "        h = torch.tanh(emb.view(1,-1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits,dim=1)\n",
    "        ix = torch.multinomial(probs,num_samples=1,replacement=True,generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if(ix == 0):\n",
    "            break\n",
    "    print(\"\".join([itos[i] for i in out]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7108,  0.1226,  0.0958, -0.2214,  1.1474],\n",
       "        [ 0.3368,  0.0491,  0.0233, -0.2686, -0.6203],\n",
       "        [ 0.8205,  0.5875, -0.4193, -0.0729,  0.0642]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3,5)\n",
    "torch.nn.init.kaiming_normal_(w,mode='fan_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self,fan_in,fan_out,bias=True):\n",
    "        self.weights = torch.randn((fan_in,fan_out),generator=g) / fan_in**0.5\n",
    "        self.bias = torch.zeros(fan_in) if bias else None\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weights\n",
    "        if self.bias:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return([self.weights] + ([] if self.bias is None else [self.bias]))\n",
    "class BatchNoram1d:\n",
    "    def __init__(self,dim,eps=1e-5,momentum = 0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "    def __call__(self, x ):\n",
    "        if self.training:\n",
    "            xmean = x.mean(0,keepdim=True)\n",
    "            xvar = x.std(0,keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar+self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update the buffers\n",
    "        if self.training:\n",
    "          with torch.no_grad():\n",
    "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return([self.gamma,self.beta])\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    def parameters():\n",
    "        return []\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_emb = 2\n",
    "vocab_size = 27\n",
    "n_hidden = 100\n",
    "C = torch.randn((vocab_size,n_emb))\n",
    "layers = [\n",
    "    Linear(n_emb*block_size , n_hidden,False) , BatchNoram1d(n_hidden) , Tanh(),\n",
    "    Linear(n_hidden , n_hidden,False) , BatchNoram1d(n_hidden) , Tanh(),\n",
    "    Linear(n_hidden , n_hidden,False) , BatchNoram1d(n_hidden) , Tanh(),\n",
    "    Linear(n_hidden , n_hidden,False) , BatchNoram1d(n_hidden) , Tanh(),\n",
    "    Linear(n_hidden , vocab_size) , BatchNoram1d(n_hidden)\n",
    "]\n",
    "\n",
    "parameters =[C] + [p for l in layers for p in l.parameters()]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 5000\n",
    "batch_size = 32\n",
    "for i in range(max_steps):\n",
    "    ix = torch.randint(0,Xtr.shape[0],(batch_size,))\n",
    "    Xb , Yb = Xtr[ix] , Ytr[ix]\n",
    "    emb = C[Xb]\n",
    "    x = emb.view(-1,block_size*n_emb)\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x,Yb)\n",
    "\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0]*block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        x = emb.view(-1,block_size*n_emb)\n",
    "        for layer in layers:\n",
    "            x = layer(x)\n",
    "        logits = x\n",
    "        probs = F.softmax(logits)\n",
    "        ix = torch.multinomial(probs,1).item()\n",
    "        out.append(itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "        if(ix == 0):\n",
    "            break\n",
    "    print(\"\".join([out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "w = torch.rand(10)\n",
    "a = torch.randn((4,10))\n",
    "k = a + w\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
